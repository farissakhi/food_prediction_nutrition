{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food Classifier: Training, Evaluation, and Prediction\n",
    "\n",
    "Notebook ini menggabungkan proses training dan prediksi menjadi satu.\n",
    "\n",
    "Fitur:\n",
    "- Train 3 model (EfficientNetB0, MobileNetV2, ResNet50V2) dan pilih akurasi terbaik.\n",
    "- Dataset di `data/dataset_gambar/` dengan subfolder `train/`, `valid/`, `test/`.\n",
    "- Simpan model terbaik ke `models/best_model.keras` dan class names ke `models/class_names.json`.\n",
    "- Prediksi gambar dan integrasi nutrisi dari `data/Nutrition.csv` (per 100g) dengan opsi kustomisasi.\n",
    "- Dapat digunakan oleh Streamlit app di `app/streamlit_app.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfigurasi path\n",
    "from pathlib import Path\n",
    "BASE_DIR = Path('c:/Users/LQO/food_predictor')\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "IMG_DIR = DATA_DIR / 'dataset_gambar'\n",
    "MODELS_DIR = BASE_DIR / 'models'\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "NUTRITION_CSV = DATA_DIR / 'Nutrition.csv'\n",
    "print('DATA_DIR:', DATA_DIR)\n",
    "print('IMG_DIR:', IMG_DIR)\n",
    "print('MODELS_DIR:', MODELS_DIR)\n",
    "print('NUTRITION_CSV:', NUTRITION_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import EfficientNetB0, MobileNetV2, ResNet50V2\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as preprocess_efficient\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as preprocess_mobilenet\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input as preprocess_resnet\n",
    "import matplotlib.pyplot as plt\n",
    "import os, shutil\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "SEED = 42\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "PATIENCE = 3\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    IMG_DIR / 'train',\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    IMG_DIR / 'valid',\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    IMG_DIR / 'test',\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "class_names = train_ds.class_names\n",
    "print('Classes:', class_names)\n",
    "# Cache/prefetch\n",
    "def prepare(ds):\n",
    "    return ds.cache().prefetch(AUTOTUNE)\n",
    "train_ds_prep = prepare(train_ds)\n",
    "val_ds_prep = prepare(val_ds)\n",
    "test_ds_prep = prepare(test_ds)\n",
    "# Save class names for inference\n",
    "with open(MODELS_DIR / 'class_names.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(class_names, f, ensure_ascii=False, indent=2)\n",
    "(MODELS_DIR / 'class_names.json').as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "], name='data_augmentation')\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper untuk build model transfer learning\n",
    "def build_model(arch: str):\n",
    "    inputs = keras.Input(shape=(*IMG_SIZE, 3))\n",
    "    x = data_augmentation(inputs)\n",
    "    if arch == 'efficientnetb0':\n",
    "        base = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(*IMG_SIZE, 3))\n",
    "        preprocess = preprocess_efficient\n",
    "    elif arch == 'mobilenetv2':\n",
    "        base = MobileNetV2(include_top=False, weights='imagenet', input_shape=(*IMG_SIZE, 3))\n",
    "        preprocess = preprocess_mobilenet\n",
    "    elif arch == 'resnet50v2':\n",
    "        base = ResNet50V2(include_top=False, weights='imagenet', input_shape=(*IMG_SIZE, 3))\n",
    "        preprocess = preprocess_resnet\n",
    "    else:\n",
    "        raise ValueError('Unknown arch')\n",
    "    # Preprocess before base\n",
    "    x = layers.Lambda(preprocess, name=arch + '_preprocess')(x)\n",
    "    base.trainable = False\n",
    "    x = base(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = keras.Model(inputs, outputs, name=f'{arch}_clf')\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(1e-3),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=PATIENCE, restore_best_weights=True, monitor='val_accuracy')\n",
    "]\n",
    "archs = ['efficientnetb0', 'mobilenetv2', 'resnet50v2']\n",
    "histories = {}\n",
    "val_accuracies = {}\n",
    "saved_models = {}\n",
    "for arch in archs:\n",
    "    print(f'\\nTraining {arch} ...')\n",
    "    model = build_model(arch)\n",
    "    ckpt_path = MODELS_DIR / f'{arch}.keras'\n",
    "    ckpt_cb = keras.callbacks.ModelCheckpoint(ckpt_path.as_posix(), monitor='val_accuracy', save_best_only=True)\n",
    "    hist = model.fit(\n",
    "        train_ds_prep,\n",
    "        validation_data=val_ds_prep,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks + [ckpt_cb]\n",
    "    )\n",
    "    histories[arch] = hist.history\n",
    "    # evaluate best checkpoint\n",
    "    best_model = keras.models.load_model(ckpt_path.as_posix())\n",
    "    _, val_acc = best_model.evaluate(val_ds_prep, verbose=0)\n",
    "    val_accuracies[arch] = float(val_acc)\n",
    "    saved_models[arch] = ckpt_path.as_posix()\n",
    "\n",
    "val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pilih model terbaik dan simpan sebagai best_model.keras\n",
    "best_arch = max(val_accuracies, key=val_accuracies.get)\n",
    "print('Best arch:', best_arch, 'val_acc=', val_accuracies[best_arch])\n",
    "best_model_path = MODELS_DIR / f'{best_arch}.keras'\n",
    "best_model = keras.models.load_model(best_model_path.as_posix())\n",
    "final_path = MODELS_DIR / 'best_model.keras'\n",
    "shutil.copy(best_model_path, final_path)\n",
    "final_path.as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc = best_model.evaluate(test_ds_prep, verbose=1)\n",
    "print({'test_loss': float(test_loss), 'test_acc': float(test_acc)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Nutrition CSV dan buat mapping\n",
    "nutri_df = pd.read_csv(NUTRITION_CSV)\n",
    "# pastikan kolom food_name sesuai dengan class_names\n",
    "nutri_map = {row['food_name']: {\n",
    "    'calories': float(row['calories']),\n",
    "    'protein': float(row['protein']),\n",
    "    'fat': float(row['fat']),\n",
    "    'carbs': float(row['carbs']),\n",
    "} for _, row in nutri_df.iterrows()}\n",
    "list(nutri_map.items())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util prediksi dari image path atau array\n",
    "from PIL import Image\n",
    "def load_image_for_model(img_path_or_bytes):\n",
    "    if isinstance(img_path_or_bytes, (str, Path)):\n",
    "        img = Image.open(img_path_or_bytes).convert('RGB')\n",
    "    else:\n",
    "        img = Image.open(img_path_or_bytes).convert('RGB')\n",
    "    img = img.resize(IMG_SIZE)\n",
    "    arr = np.array(img).astype('float32')\n",
    "    return arr\n",
    "\n",
    "def predict_image(img_path_or_bytes, grams: float = 100.0, custom_per100g: dict | None = None):\n",
    "    class_path = MODELS_DIR / 'class_names.json'\n",
    "    with open(class_path, 'r', encoding='utf-8') as f:\n",
    "        cls = json.load(f)\n",
    "    model = keras.models.load_model((MODELS_DIR / 'best_model.keras').as_posix())\n",
    "    arr = load_image_for_model(img_path_or_bytes)\n",
    "    x = np.expand_dims(arr, 0)\n",
    "    # pilih preprocess berdasar arsitektur dari nama file best\n",
    "    best_name = None\n",
    "    for cand in ['efficientnetb0', 'mobilenetv2', 'resnet50v2']:\n",
    "        if (MODELS_DIR / f'{cand}.keras').exists():\n",
    "            if os.path.samefile((MODELS_DIR / f'{cand}.keras'), (MODELS_DIR / 'best_model.keras')):\n",
    "                best_name = cand\n",
    "                break\n",
    "    if best_name == 'efficientnetb0':\n",
    "        x = preprocess_efficient(x)\n",
    "    elif best_name == 'mobilenetv2':\n",
    "        x = preprocess_mobilenet(x)\n",
    "    else:\n",
    "        x = preprocess_resnet(x)\n",
    "    probs = model.predict(x, verbose=0)[0]\n",
    "    idx = int(np.argmax(probs))\n",
    "    label = cls[idx]\n",
    "    conf = float(probs[idx])\n",
    "    per100 = nutri_map.get(label, {'calories': 0, 'protein': 0, 'fat': 0, 'carbs': 0})\n",
    "    if custom_per100g is not None:\n",
    "        per100 = {**per100, **{k: float(v) for k, v in custom_per100g.items() if k in per100}}\n",
    "    factor = grams / 100.0\n",
    "    per_serving = {k: round(v * factor, 2) for k, v in per100.items()}\n",
    "    return {\n",
    "        'label': label,\n",
    "        'confidence': round(conf, 4),\n",
    "        'per_100g': per100,\n",
    "        'grams': grams,\n",
    "        'per_serving': per_serving\n",
    "    }\n",
    "\n",
    "# Contoh pakai: \n",
    "# predict_image('path_ke_gambar.jpg', grams=150, custom_per100g={'calories': 120})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
